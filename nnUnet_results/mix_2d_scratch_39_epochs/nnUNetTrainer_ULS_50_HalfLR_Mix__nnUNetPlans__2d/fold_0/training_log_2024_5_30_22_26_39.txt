
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 49, 'patch_size': [256, 256], 'median_image_size_in_voxels': [255.0, 255.0], 'spacing': [0.7578125, 0.7578125], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'UNet_class_name': 'PlainConvUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2], 'num_pool_per_axis': [6, 6], 'pool_op_kernel_sizes': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'unet_max_num_features': 512, 'resampling_fn_data': 'no_resampling_data_or_seg_to_shape', 'resampling_fn_seg': 'no_resampling_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'no_resampling_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset501_RadboudumcBone', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [0.800000011920929, 0.7578125, 0.7578125], 'original_median_shape_after_transp': [128, 256, 256], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlannerNoResampling', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 2782.0, 'mean': 1175.083251953125, 'median': 1230.0, 'min': -935.0, 'percentile_00_5': 33.0, 'percentile_99_5': 2269.0, 'std': 513.393310546875}}} 
 
2024-05-30 22:26:41.306398: unpacking dataset... 
2024-05-30 22:26:58.939256: unpacking done... 
2024-05-30 22:26:58.947909: do_dummy_2d_data_aug: False 
2024-05-30 22:26:58.973148: Using splits from existing split file: /scratch-local/ljulius.6443847/nnUNet_preprocessed/Dataset501_RadboudumcBone/splits_final.json 
2024-05-30 22:26:58.974095: The split file contains 5 splits. 
2024-05-30 22:26:58.974202: Desired fold for training: 0 
2024-05-30 22:26:58.974269: This split has 557 training and 140 validation cases. 
2024-05-30 22:26:59.308139: Unable to plot network architecture: 
2024-05-30 22:26:59.308291: No module named 'IPython' 
2024-05-30 22:26:59.358966:  
2024-05-30 22:26:59.359121: Epoch 0 
2024-05-30 22:26:59.359331: Current learning rate: 0.005 
2024-05-30 22:30:26.367870: train_loss -0.2632 
2024-05-30 22:30:26.368410: val_loss -0.2444 
2024-05-30 22:30:26.368537: Pseudo dice [0.3373] 
2024-05-30 22:30:26.368650: Epoch time: 207.01 s 
2024-05-30 22:30:26.368742: Yayy! New best EMA pseudo Dice: 0.3373 
2024-05-30 22:30:28.266955:  
2024-05-30 22:30:28.267210: Epoch 1 
2024-05-30 22:30:28.267359: Current learning rate: 0.00491 
2024-05-30 22:33:22.726245: train_loss -0.4176 
2024-05-30 22:33:22.730911: val_loss -0.3664 
2024-05-30 22:33:22.731034: Pseudo dice [0.4253] 
2024-05-30 22:33:22.731164: Epoch time: 174.46 s 
2024-05-30 22:33:22.731258: Yayy! New best EMA pseudo Dice: 0.3461 
2024-05-30 22:33:24.504838:  
2024-05-30 22:33:24.505072: Epoch 2 
2024-05-30 22:33:24.505207: Current learning rate: 0.00482 
2024-05-30 22:36:12.107884: train_loss -0.4256 
2024-05-30 22:36:12.109443: val_loss -0.3176 
2024-05-30 22:36:12.109559: Pseudo dice [0.3674] 
2024-05-30 22:36:12.109661: Epoch time: 167.6 s 
2024-05-30 22:36:12.109748: Yayy! New best EMA pseudo Dice: 0.3482 
2024-05-30 22:36:13.986467:  
2024-05-30 22:36:13.986690: Epoch 3 
2024-05-30 22:36:13.986824: Current learning rate: 0.00473 
2024-05-30 22:39:00.028270: train_loss -0.4536 
2024-05-30 22:39:00.033052: val_loss -0.335 
2024-05-30 22:39:00.033172: Pseudo dice [0.3783] 
2024-05-30 22:39:00.033301: Epoch time: 166.04 s 
2024-05-30 22:39:00.033393: Yayy! New best EMA pseudo Dice: 0.3512 
2024-05-30 22:39:01.837539:  
2024-05-30 22:39:01.837755: Epoch 4 
2024-05-30 22:39:01.837887: Current learning rate: 0.00464 
2024-05-30 22:41:51.584094: train_loss -0.4477 
2024-05-30 22:41:51.590491: val_loss -0.3524 
2024-05-30 22:41:51.590615: Pseudo dice [0.4006] 
2024-05-30 22:41:51.590721: Epoch time: 169.75 s 
2024-05-30 22:41:51.590817: Yayy! New best EMA pseudo Dice: 0.3562 
2024-05-30 22:41:53.451372:  
2024-05-30 22:41:53.451674: Epoch 5 
2024-05-30 22:41:53.451810: Current learning rate: 0.00455 
2024-05-30 22:44:38.545518: train_loss -0.4654 
2024-05-30 22:44:38.546061: val_loss -0.2972 
2024-05-30 22:44:38.546177: Pseudo dice [0.3393] 
2024-05-30 22:44:38.546286: Epoch time: 165.1 s 
2024-05-30 22:44:40.015290:  
2024-05-30 22:44:40.015512: Epoch 6 
2024-05-30 22:44:40.015655: Current learning rate: 0.00446 
2024-05-30 22:47:28.459910: train_loss -0.4798 
2024-05-30 22:47:28.460874: val_loss -0.3127 
2024-05-30 22:47:28.460995: Pseudo dice [0.3529] 
2024-05-30 22:47:28.461105: Epoch time: 168.45 s 
2024-05-30 22:47:29.965305:  
2024-05-30 22:47:29.965607: Epoch 7 
2024-05-30 22:47:29.965735: Current learning rate: 0.00437 
2024-05-30 22:50:21.144367: train_loss -0.4711 
2024-05-30 22:50:21.150642: val_loss -0.2789 
2024-05-30 22:50:21.150771: Pseudo dice [0.3205] 
2024-05-30 22:50:21.150906: Epoch time: 171.18 s 
2024-05-30 22:50:22.727127:  
2024-05-30 22:50:22.727357: Epoch 8 
2024-05-30 22:50:22.727492: Current learning rate: 0.00427 
2024-05-30 22:53:11.143997: train_loss -0.4481 
2024-05-30 22:53:11.144680: val_loss -0.3591 
2024-05-30 22:53:11.144802: Pseudo dice [0.4047] 
2024-05-30 22:53:11.144907: Epoch time: 168.42 s 
2024-05-30 22:53:11.144994: Yayy! New best EMA pseudo Dice: 0.3563 
2024-05-30 22:53:13.036138:  
2024-05-30 22:53:13.036336: Epoch 9 
2024-05-30 22:53:13.036463: Current learning rate: 0.00418 
2024-05-30 22:56:02.706775: train_loss -0.4818 
2024-05-30 22:56:02.711620: val_loss -0.2722 
2024-05-30 22:56:02.711738: Pseudo dice [0.3133] 
2024-05-30 22:56:02.711874: Epoch time: 169.67 s 
2024-05-30 22:56:04.210202:  
2024-05-30 22:56:04.210486: Epoch 10 
2024-05-30 22:56:04.210614: Current learning rate: 0.00409 
2024-05-30 22:58:48.878512: train_loss -0.4818 
2024-05-30 22:58:48.879296: val_loss -0.366 
2024-05-30 22:58:48.879419: Pseudo dice [0.3989] 
2024-05-30 22:58:48.879527: Epoch time: 164.67 s 
2024-05-30 22:58:48.879617: Yayy! New best EMA pseudo Dice: 0.3567 
2024-05-30 22:58:50.656230:  
2024-05-30 22:58:50.656421: Epoch 11 
2024-05-30 22:58:50.656546: Current learning rate: 0.004 
2024-05-30 23:01:32.093328: train_loss -0.4979 
2024-05-30 23:01:32.098718: val_loss -0.3435 
2024-05-30 23:01:32.098851: Pseudo dice [0.3824] 
2024-05-30 23:01:32.098982: Epoch time: 161.44 s 
2024-05-30 23:01:32.099076: Yayy! New best EMA pseudo Dice: 0.3593 
2024-05-30 23:01:33.903284:  
2024-05-30 23:01:33.903601: Epoch 12 
2024-05-30 23:01:33.903728: Current learning rate: 0.00391 
2024-05-30 23:06:16.736381: train_loss -0.5076 
2024-05-30 23:06:16.737152: val_loss -0.3536 
2024-05-30 23:06:16.737275: Pseudo dice [0.4014] 
2024-05-30 23:06:16.737383: Epoch time: 282.83 s 
2024-05-30 23:06:16.737470: Yayy! New best EMA pseudo Dice: 0.3635 
2024-05-30 23:06:18.544341:  
2024-05-30 23:06:18.544776: Epoch 13 
2024-05-30 23:06:18.544912: Current learning rate: 0.00381 
2024-05-30 23:09:05.241698: train_loss -0.5048 
2024-05-30 23:09:05.246494: val_loss -0.3035 
2024-05-30 23:09:05.246618: Pseudo dice [0.3493] 
2024-05-30 23:09:05.246743: Epoch time: 166.7 s 
2024-05-30 23:09:06.787402:  
2024-05-30 23:09:06.787612: Epoch 14 
2024-05-30 23:09:06.787740: Current learning rate: 0.00372 
2024-05-30 23:11:51.181534: train_loss -0.4923 
2024-05-30 23:11:51.182333: val_loss -0.379 
2024-05-30 23:11:51.182445: Pseudo dice [0.4158] 
2024-05-30 23:11:51.182549: Epoch time: 164.4 s 
2024-05-30 23:11:51.182635: Yayy! New best EMA pseudo Dice: 0.3674 
2024-05-30 23:11:53.033645:  
2024-05-30 23:11:53.033859: Epoch 15 
2024-05-30 23:11:53.033987: Current learning rate: 0.00363 
2024-05-30 23:14:32.177461: train_loss -0.5102 
2024-05-30 23:14:32.182605: val_loss -0.3781 
2024-05-30 23:14:32.182726: Pseudo dice [0.4262] 
2024-05-30 23:14:32.182861: Epoch time: 159.15 s 
2024-05-30 23:14:32.182953: Yayy! New best EMA pseudo Dice: 0.3733 
2024-05-30 23:14:34.042820:  
2024-05-30 23:14:34.043676: Epoch 16 
2024-05-30 23:14:34.043878: Current learning rate: 0.00353 
2024-05-30 23:17:15.260756: train_loss -0.4899 
2024-05-30 23:17:15.261445: val_loss -0.355 
2024-05-30 23:17:15.261566: Pseudo dice [0.3973] 
2024-05-30 23:17:15.261672: Epoch time: 161.22 s 
2024-05-30 23:17:15.261760: Yayy! New best EMA pseudo Dice: 0.3757 
2024-05-30 23:17:17.143173:  
2024-05-30 23:17:17.143382: Epoch 17 
2024-05-30 23:17:17.143506: Current learning rate: 0.00344 
2024-05-30 23:20:04.422888: train_loss -0.5101 
2024-05-30 23:20:04.429075: val_loss -0.3639 
2024-05-30 23:20:04.429198: Pseudo dice [0.4138] 
2024-05-30 23:20:04.429334: Epoch time: 167.28 s 
2024-05-30 23:20:04.429429: Yayy! New best EMA pseudo Dice: 0.3795 
2024-05-30 23:20:06.414396:  
2024-05-30 23:20:06.414607: Epoch 18 
2024-05-30 23:20:06.414733: Current learning rate: 0.00335 
2024-05-30 23:22:53.216380: train_loss -0.5165 
2024-05-30 23:22:53.217196: val_loss -0.3574 
2024-05-30 23:22:53.217312: Pseudo dice [0.3967] 
2024-05-30 23:22:53.217415: Epoch time: 166.8 s 
2024-05-30 23:22:53.217502: Yayy! New best EMA pseudo Dice: 0.3812 
2024-05-30 23:22:55.071416:  
2024-05-30 23:22:55.071730: Epoch 19 
2024-05-30 23:22:55.071872: Current learning rate: 0.00325 
2024-05-30 23:25:39.616604: train_loss -0.5312 
2024-05-30 23:25:39.621442: val_loss -0.345 
2024-05-30 23:25:39.621574: Pseudo dice [0.3771] 
2024-05-30 23:25:39.621709: Epoch time: 164.55 s 
2024-05-30 23:25:41.212897:  
2024-05-30 23:25:41.213098: Epoch 20 
2024-05-30 23:25:41.213224: Current learning rate: 0.00316 
2024-05-30 23:28:24.481972: train_loss -0.5125 
2024-05-30 23:28:24.483036: val_loss -0.3797 
2024-05-30 23:28:24.483151: Pseudo dice [0.4313] 
2024-05-30 23:28:24.483252: Epoch time: 163.27 s 
2024-05-30 23:28:24.483335: Yayy! New best EMA pseudo Dice: 0.3859 
2024-05-30 23:28:26.477072:  
2024-05-30 23:28:26.477338: Epoch 21 
2024-05-30 23:28:26.477470: Current learning rate: 0.00306 
2024-05-30 23:31:09.888091: train_loss -0.5303 
2024-05-30 23:31:09.890336: val_loss -0.3469 
2024-05-30 23:31:09.890457: Pseudo dice [0.3937] 
2024-05-30 23:31:09.890591: Epoch time: 163.41 s 
2024-05-30 23:31:09.890685: Yayy! New best EMA pseudo Dice: 0.3866 
2024-05-30 23:31:11.804655:  
2024-05-30 23:31:11.804912: Epoch 22 
2024-05-30 23:31:11.805053: Current learning rate: 0.00297 
2024-05-30 23:33:59.341523: train_loss -0.5429 
2024-05-30 23:33:59.346166: val_loss -0.3596 
2024-05-30 23:33:59.346286: Pseudo dice [0.3983] 
2024-05-30 23:33:59.346391: Epoch time: 167.54 s 
2024-05-30 23:33:59.346484: Yayy! New best EMA pseudo Dice: 0.3878 
2024-05-30 23:34:01.237231:  
2024-05-30 23:34:01.237473: Epoch 23 
2024-05-30 23:34:01.237604: Current learning rate: 0.00287 
2024-05-30 23:36:53.587070: train_loss -0.5399 
2024-05-30 23:36:53.591764: val_loss -0.3553 
2024-05-30 23:36:53.591886: Pseudo dice [0.4181] 
2024-05-30 23:36:53.592013: Epoch time: 172.35 s 
2024-05-30 23:36:53.592101: Yayy! New best EMA pseudo Dice: 0.3908 
2024-05-30 23:36:55.353470:  
2024-05-30 23:36:55.353674: Epoch 24 
2024-05-30 23:36:55.353810: Current learning rate: 0.00278 
2024-05-30 23:39:51.395642: train_loss -0.5407 
2024-05-30 23:39:51.396526: val_loss -0.3583 
2024-05-30 23:39:51.396654: Pseudo dice [0.4] 
2024-05-30 23:39:51.396763: Epoch time: 176.04 s 
2024-05-30 23:39:51.396865: Yayy! New best EMA pseudo Dice: 0.3917 
2024-05-30 23:39:53.193230:  
2024-05-30 23:39:53.193964: Epoch 25 
2024-05-30 23:39:53.194099: Current learning rate: 0.00268 
2024-05-30 23:42:44.717053: train_loss -0.5508 
2024-05-30 23:42:44.721796: val_loss -0.4141 
2024-05-30 23:42:44.721915: Pseudo dice [0.4528] 
2024-05-30 23:42:44.722042: Epoch time: 171.53 s 
2024-05-30 23:42:44.722131: Yayy! New best EMA pseudo Dice: 0.3979 
2024-05-30 23:42:46.839299:  
2024-05-30 23:42:46.839492: Epoch 26 
2024-05-30 23:42:46.839614: Current learning rate: 0.00258 
2024-05-30 23:45:32.627791: train_loss -0.558 
2024-05-30 23:45:32.628537: val_loss -0.3617 
2024-05-30 23:45:32.628663: Pseudo dice [0.414] 
2024-05-30 23:45:32.628784: Epoch time: 165.79 s 
2024-05-30 23:45:32.628883: Yayy! New best EMA pseudo Dice: 0.3995 
2024-05-30 23:45:34.434920:  
2024-05-30 23:45:34.435112: Epoch 27 
2024-05-30 23:45:34.435236: Current learning rate: 0.00249 
2024-05-30 23:48:22.175838: train_loss -0.5633 
2024-05-30 23:48:22.180395: val_loss -0.3715 
2024-05-30 23:48:22.180515: Pseudo dice [0.4099] 
2024-05-30 23:48:22.180645: Epoch time: 167.74 s 
2024-05-30 23:48:22.180737: Yayy! New best EMA pseudo Dice: 0.4005 
2024-05-30 23:48:23.999180:  
2024-05-30 23:48:23.999368: Epoch 28 
2024-05-30 23:48:23.999494: Current learning rate: 0.00239 
2024-05-30 23:51:43.186310: train_loss -0.5737 
2024-05-30 23:51:43.191028: val_loss -0.3836 
2024-05-30 23:51:43.191144: Pseudo dice [0.4297] 
2024-05-30 23:51:43.191244: Epoch time: 199.19 s 
2024-05-30 23:51:43.191591: Yayy! New best EMA pseudo Dice: 0.4034 
2024-05-30 23:51:45.015506:  
2024-05-30 23:51:45.015712: Epoch 29 
2024-05-30 23:51:45.015845: Current learning rate: 0.00229 
2024-05-30 23:55:14.608012: train_loss -0.5674 
2024-05-30 23:55:14.612800: val_loss -0.3253 
2024-05-30 23:55:14.612920: Pseudo dice [0.3706] 
2024-05-30 23:55:14.613051: Epoch time: 209.59 s 
2024-05-30 23:55:16.175459:  
2024-05-30 23:55:16.175656: Epoch 30 
2024-05-30 23:55:16.175782: Current learning rate: 0.00219 
2024-05-30 23:58:07.525990: train_loss -0.573 
2024-05-30 23:58:07.526714: val_loss -0.3844 
2024-05-30 23:58:07.526838: Pseudo dice [0.4189] 
2024-05-30 23:58:07.526945: Epoch time: 171.35 s 
2024-05-30 23:58:09.109455:  
2024-05-30 23:58:09.109671: Epoch 31 
2024-05-30 23:58:09.109805: Current learning rate: 0.00209 
2024-05-31 00:00:51.625268: train_loss -0.581 
2024-05-31 00:00:51.629927: val_loss -0.3784 
2024-05-31 00:00:51.630056: Pseudo dice [0.4213] 
2024-05-31 00:00:51.630190: Epoch time: 162.52 s 
2024-05-31 00:00:51.630282: Yayy! New best EMA pseudo Dice: 0.404 
2024-05-31 00:00:53.530925:  
2024-05-31 00:00:53.531146: Epoch 32 
2024-05-31 00:00:53.531311: Current learning rate: 0.00199 
2024-05-31 00:03:33.797507: train_loss -0.5766 
2024-05-31 00:03:33.798329: val_loss -0.3524 
2024-05-31 00:03:33.798453: Pseudo dice [0.3965] 
2024-05-31 00:03:33.798566: Epoch time: 160.27 s 
2024-05-31 00:03:35.372717:  
2024-05-31 00:03:35.373063: Epoch 33 
2024-05-31 00:03:35.373196: Current learning rate: 0.00189 
2024-05-31 00:06:17.116524: train_loss -0.582 
2024-05-31 00:06:17.122813: val_loss -0.4008 
2024-05-31 00:06:17.122930: Pseudo dice [0.443] 
2024-05-31 00:06:17.123055: Epoch time: 161.75 s 
2024-05-31 00:06:17.123146: Yayy! New best EMA pseudo Dice: 0.4072 
2024-05-31 00:06:18.963326:  
2024-05-31 00:06:18.963523: Epoch 34 
2024-05-31 00:06:18.963650: Current learning rate: 0.00179 
2024-05-31 00:09:00.545685: train_loss -0.5808 
2024-05-31 00:09:00.547615: val_loss -0.359 
2024-05-31 00:09:00.547733: Pseudo dice [0.3988] 
2024-05-31 00:09:00.547843: Epoch time: 161.58 s 
2024-05-31 00:09:02.114497:  
2024-05-31 00:09:02.114723: Epoch 35 
2024-05-31 00:09:02.114862: Current learning rate: 0.00169 
2024-05-31 00:11:41.495214: train_loss -0.5946 
2024-05-31 00:11:41.499678: val_loss -0.3809 
2024-05-31 00:11:41.499822: Pseudo dice [0.4263] 
2024-05-31 00:11:41.499954: Epoch time: 159.38 s 
2024-05-31 00:11:41.500049: Yayy! New best EMA pseudo Dice: 0.4083 
2024-05-31 00:11:43.374901:  
2024-05-31 00:11:43.375083: Epoch 36 
2024-05-31 00:11:43.375208: Current learning rate: 0.00159 
2024-05-31 00:14:39.510997: train_loss -0.5904 
2024-05-31 00:14:39.511624: val_loss -0.3337 
2024-05-31 00:14:39.511737: Pseudo dice [0.3746] 
2024-05-31 00:14:39.511847: Epoch time: 176.14 s 
2024-05-31 00:14:41.095946:  
2024-05-31 00:14:41.096140: Epoch 37 
2024-05-31 00:14:41.096265: Current learning rate: 0.00149 
2024-05-31 00:17:23.774093: train_loss -0.6093 
2024-05-31 00:17:23.778572: val_loss -0.3899 
2024-05-31 00:17:23.778721: Pseudo dice [0.4403] 
2024-05-31 00:17:23.778874: Epoch time: 162.68 s 
2024-05-31 00:17:23.778975: Yayy! New best EMA pseudo Dice: 0.4085 
2024-05-31 00:17:25.719371:  
2024-05-31 00:17:25.719594: Epoch 38 
2024-05-31 00:17:25.719720: Current learning rate: 0.00138 
2024-05-31 00:21:44.733707: train_loss -0.6014 
2024-05-31 00:21:44.734486: val_loss -0.4473 
2024-05-31 00:21:44.734609: Pseudo dice [0.5006] 
2024-05-31 00:21:44.734719: Epoch time: 259.02 s 
2024-05-31 00:21:44.734817: Yayy! New best EMA pseudo Dice: 0.4177 
2024-05-31 00:21:47.120558:  
2024-05-31 00:21:47.120951: Epoch 39 
2024-05-31 00:21:47.121090: Current learning rate: 0.00128 
